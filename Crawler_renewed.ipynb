{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проект. Анна Запорощенко, Софья Генералова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка текстов\n",
    "\n",
    "Вам нужно собрать свой корпус текстов (100 штук не менее 100 слов каждый / 10 000 словоупотреблений). Корпус состоит из текстов одного жанра или тематики (не отрывки одного текста).\n",
    "\n",
    "Можно делать это вручную или скачивая html-страницы средствами Питона (например, библиотека requests). Затем нужно удалить нетекстовые элементы, разделить корпус на предложения. Не забудьте, что для каждого предложения нужно помнить, из какого источника оно берется.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "xsp_cNjmJQqu",
    "outputId": "c9256b14-2a54-4373-ddfd-f2ba50572848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fake_useragent in c:\\users\\vadik\\anaconda3\\lib\\site-packages (0.1.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UEhRQFg2In2d"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EesF-BR-Ikl1"
   },
   "outputs": [],
   "source": [
    "# функция возвращает html код страницы\n",
    "def get_html_content(url):\n",
    "    user_agent = UserAgent().chrome\n",
    "    req = urllib.request.Request(url, headers={'User-Agent':user_agent})\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        html_content = response.read().decode('utf-8')\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2g4hkEeng199"
   },
   "outputs": [],
   "source": [
    "# функция возвращает ссылки на новости, собранные на странице\n",
    "def get_links(html_content, pattern, links):\n",
    "    l = re.findall(pattern, html_content)\n",
    "    links.extend(l)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rbklytX2LMgN"
   },
   "outputs": [],
   "source": [
    "# инициализируем список для ссылок\n",
    "# генерируем номера страниц со ссылками на новости (первая без номера, ее оставим) и достаем ссылки из них\n",
    "links = []\n",
    "pages = [t for t in range(2,7)]\n",
    "pattern = '<a href=\\'(.+?)\\'><h3 class=\"news-big\"'\n",
    "for n in pages:\n",
    "    url = 'https://liveberlin.ru/news/'\n",
    "    url = url + 'page/' + str(n)\n",
    "    links = get_links(get_html_content(url), pattern, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HscTmvYRnct4"
   },
   "outputs": [],
   "source": [
    "# функция убирает нерасшифровавшиеся знаки, рекламу, теги в строке\n",
    "def clear(line):\n",
    "    line = line.replace('&nbsp;', ' ')\n",
    "    line = line.replace('&#8217;', \"'\")\n",
    "    line = line.replace('\\xa0', ' ')\n",
    "    line = re.split('<.+?>', line)\n",
    "    line = ('').join(line)\n",
    "    line = line.replace(' Реклама в «Живом Берлине» | liveberlin.ad@gmail.com', '')\n",
    "    line = re.sub('\\s+', ' ',line) # убирает повторяющиеся пробельные символы\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nlwgV9btls0a"
   },
   "outputs": [],
   "source": [
    "# функция достает из html кода новостной страницы текст новости и заголовок\n",
    "def get_info(html_content):\n",
    "    text = clear((' ').join(re.findall('<p>.+?</p>', html_content)[:-2]))\n",
    "    title = clear(('').join(re.findall(\"<meta property=\\'og:type\\' content=\\'article\\' />\\n    <meta property=\\'og:title\\' content=\\'(.+?)' />\", html_content)))\n",
    "    return text, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i56fB4kqrd-O"
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aUJftxfirDry"
   },
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    html_content = get_html_content(link)\n",
    "    text, title = get_info(html_content)\n",
    "    texts.append(text)\n",
    "    titles.append(title + '\\n' + link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Морфологический анализ текстов\n",
    "\n",
    "Здесь можно использовать любой инструмент / библиотеку, которая позволяет проводить морфологический анализ.\n",
    "Подумайте, нужно ли вам разрешение морфологической неоднозначности. Хорошо бы сказать об этом в презентации и обосновать выбранное решение.\n",
    "Не забудьте, что для запросов тоже понадобится морфологический анализ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natasha делит по предложениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "morph_vocab = MorphVocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделать ф-ю: sent_a(doc, text_meta, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sent_a(doc, text_meta, start=0):\n",
    "    next_start = 0\n",
    "    for sent_id, sent in enumerate(doc.sents, start):\n",
    "        next_start = sent_id\n",
    "        sent_text = sent.text\n",
    "#         print(sent_text)\n",
    "        sentence = []\n",
    "        for tok in sent.tokens:\n",
    "            pos = tok.pos\n",
    "            if pos != 'PUNCT':\n",
    "                tok.lemmatize(morph_vocab)\n",
    "                lem = tok.lemma\n",
    "                tex = tok.text\n",
    "                sentence.append(tex + '<pos:' + pos + '>' + '<lem:' + lem + '>')\n",
    "        # ДЕЛИТ НА ЭНГРАММЫ\n",
    "        sent_n_gramm(sentence, sent_text, sent_id, text_meta)\n",
    "        \n",
    "    return next_start+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_n_gramm(mas_for_sent, sent_text, sent_id, text_meta):\n",
    "    rr = []\n",
    "    ln = len(mas_for_sent)\n",
    "    if ln < 3 and ln > 0:\n",
    "        rr.append(' '.join(mas_for_sent))\n",
    "    else:\n",
    "        for i in range(ln):\n",
    "            if i < ln-2:\n",
    "                res = mas_for_sent[i] + ' ' + mas_for_sent[i+1] + ' ' + mas_for_sent[i+2]\n",
    "                rr.append(res)\n",
    "                \n",
    "    for n_gr in rr:\n",
    "        ws = n_gr.split('> ')\n",
    "        ngrm = [] # list from which i will concatenate strs\n",
    "        for w in ws: # для кажд части энграммы\n",
    "            w_text = re.search('([^<>]+)<', w).group(1)\n",
    "            ngrm.append(w_text)\n",
    "    \n",
    "        ngrm_s = ' '.join(ngrm)\n",
    "        if ngrm_s not in big_dict:\n",
    "            big_dict[ngrm_s] = {'sent_id': [], 'text_meta':[], 'sent_text':[], 'tag_ngr':[]}\n",
    "            \n",
    "        if sent_id not in big_dict[ngrm_s]['sent_id'] or n_gr not in big_dict[ngrm_s]['tag_ngr']:\n",
    "            big_dict[ngrm_s]['sent_id'].append(sent_id)\n",
    "            big_dict[ngrm_s]['text_meta'].append(text_meta)\n",
    "            big_dict[ngrm_s]['sent_text'].append(sent_text)\n",
    "            big_dict[ngrm_s]['tag_ngr'].append(n_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_start = 0\n",
    "for text, text_meta in zip(texts, titles):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    next_start = sent_a(doc, text_meta, next_start) # след начальный айди предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13782"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13782 3gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подключаемся к базе данных\n",
    "conn = sqlite3.connect('project_db.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "таблица для предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x22376a75340>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"CREATE TABLE IF NOT EXISTS 'Sentences'('sent_id' integer PRIMARY KEY AUTOINCREMENT, 'title_link', 'sent_orig')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "таблица энграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x22376a75340>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"CREATE TABLE IF NOT EXISTS 'Corpus'('ngr_id' integer PRIMARY KEY AUTOINCREMENT, '3-gram0_orig', '3-gram1_orig', '3-gram2_orig', '3-gram0_lem', '3-gram1_lem', '3-gram2_lem', '3-gram0_pos', '3-gram1_pos', '3-gram2_pos', 'sent' integer, FOREIGN KEY('sent') REFERENCES 'Sentences'('sent_id'))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "из словаря big_dict все записывается в бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('project_db.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "countt = 0 # счетчик для энграмм\n",
    "for gr in big_dict:\n",
    "    for i in range(len(big_dict[gr]['sent_id'])):\n",
    "        sent_id = big_dict[gr]['sent_id'][i]\n",
    "            \n",
    "        title_link = big_dict[gr]['text_meta'][i]\n",
    "        sent_orig = big_dict[gr]['sent_text'][i]\n",
    "        ngr_id = big_dict[gr]['tag_ngr'][i]\n",
    "        \n",
    "        ws = ngr_id.split('> ')\n",
    "        \n",
    "        # могут быть не только триграммы, но и биграммы, униграммы (теоретически - если предложение состояло из 1-2 слов)\n",
    "        \n",
    "        n_gram1_orig, n_gram1_lem, n_gram1_pos = '', '', ''\n",
    "        n_gram2_orig, n_gram2_lem, n_gram2_pos = '', '', ''\n",
    "        \n",
    "        for j in range(len(ws)):\n",
    "            w_text = re.search('([^<>]+)<', ws[j]).group(1)\n",
    "            pos = re.search('<pos:([^>]+)>', ws[j]).group(1)\n",
    "            lem = re.search('<lem:([^>]+)>?', ws[j]).group(1)\n",
    "            if j == 0:\n",
    "                n_gram0_orig = w_text\n",
    "                n_gram0_lem = lem\n",
    "                n_gram0_pos = pos\n",
    "            elif j == 1:\n",
    "                n_gram1_orig = w_text\n",
    "                n_gram1_lem = lem\n",
    "                n_gram1_pos = pos\n",
    "            else:\n",
    "                n_gram2_orig = w_text\n",
    "                n_gram2_lem = lem\n",
    "                n_gram2_pos = pos\n",
    "        \n",
    "        c.execute('INSERT OR IGNORE INTO \"Sentences\" VALUES (?, ?, ?)', (sent_id, title_link, sent_orig)) \n",
    "        # если попробует добавить с повт праймари ки, то проигнорит\n",
    "        c.execute('INSERT INTO \"Corpus\" VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', (countt, n_gram0_orig, n_gram1_orig, n_gram2_orig, n_gram0_lem, n_gram1_lem, n_gram2_lem, n_gram0_pos, n_gram1_pos, n_gram2_pos, sent_id))\n",
    "        conn.commit()\n",
    "        countt += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### указать какой набор тегов / стандарт разметки вы используете. Иногда достаточно ссылки на библиотеку (например, тегсет Mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### функция для поиска\n",
    "\n",
    "поиск - нужно найти все предложения, где слово встречается в любой форме\n",
    "“поиска” - нужно найти предложения только с этой формой\n",
    "знать+NOUN - нужно найти все предложения, где встречается существительное “знать”\n",
    "NOUN - найти все предложения с существительными\n",
    "\n",
    "В питоне это, скорее всего, будет выглядеть так:\n",
    "search(‘поиск’)\n",
    "search(‘“поиск”’) - дублируем кавычки\n",
    "search(‘знать+NOUN’)\n",
    "search(‘NOUN VERB ADVB’)\n",
    "search(‘ADJ дом’)\n",
    "\n",
    "Запрос состоит из последовательных слов/POS-тегов (n-грамма,  максимум 3-грамма), к каждому применяются правила выше."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Запросы могут состоять из \n",
    "\n",
    "1) леммы/словоформы (тогда нужно найти вхождения во всех формах), \n",
    "\n",
    "2) словоформы/фразы в двойных кавычках (тогда нужно найти только заданную форму), \n",
    "\n",
    "3) леммы и POS-тега (тогда нужно найти все формы, отмеченные данным тегом).\n",
    "\n",
    "Выдача должна состоять из предложений с мета-информацией (например, URL страницы, откуда взят текст, или название текста + название источника - например, “Война и мир” - lib.ru)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pos = set(['ADJ',\n",
    "'ADV',\n",
    "'DET',\n",
    "'AUX',\n",
    "'CCONJ',\n",
    "'SCONJ',\n",
    "'VERB',\n",
    "'INTJ',\n",
    "'NOUN',\n",
    "'PROPN',\n",
    "'PRON',\n",
    "'NUM',\n",
    "'SYM',\n",
    "'PART',\n",
    "'ADP',\n",
    "'X']) # тег 'PUNCT' будет считаться словом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_request(input_s):\n",
    "    res_words = []\n",
    "    \n",
    "    words = input_s.split(' ') # кошек \"нет\" NOUN\n",
    "    for w_index, word in enumerate(words):\n",
    "        if word[0] == '\"':\n",
    "            if word[-1] != '\"': # если кавычка не закрыта\n",
    "                res_words = []\n",
    "                print('Попробуйте закрыть двойные кавычки')\n",
    "                return res_words\n",
    "            \n",
    "            #поиск по форме слова\n",
    "            line = \"Corpus.'3-gram@_orig' = \" + \"'\" + word.strip('\"') + \"'\"\n",
    "        elif word in list_of_pos:\n",
    "            #поиск по POS\n",
    "            line = \"Corpus.'3-gram@_pos' = \" + \"'\" + word + \"'\"\n",
    "        elif '+' in word:\n",
    "            if word[0] == '+' or word[-1] == '+': # проверкa 'кошка+', 'noun' or '+кошка', 'noun' or '+'\n",
    "                res_words = []\n",
    "                print('знак + соединяет лемму/словоформу и часть речи. напр.: ехать+NOUN')\n",
    "                return res_words\n",
    "            \n",
    "            #поиск по POS и леммам. если плюс в середине чего-то напр bbb+aaa\n",
    "            lemma, POS = word.split('+')\n",
    "            \n",
    "            # проверка на то что pos это pos\n",
    "            if POS not in list_of_pos:\n",
    "                res_words = []\n",
    "                print('знак + соединяет лемму/словоформу и часть речи. напр.: ехать+NOUN')\n",
    "                return res_words\n",
    "        \n",
    "            # проверка на то что lemma это лемма # кошкой+NOUN\n",
    "            # лемматизируем наташей\n",
    "            lem = get_lem(word)\n",
    "                \n",
    "            line = \"Corpus.'3-gram@_lem' = \" + \"'\" + lem + \"'\" + \" AND Corpus.'3-gram@_pos' = \" + \"'\" + POS + \"'\"\n",
    "            \n",
    "        else:\n",
    "            lem = get_lem(word)\n",
    "            #поиск по леммам\n",
    "            line = \"Corpus.'3-gram@_lem' = \" + \"'\" + lem + \"'\"\n",
    "        \n",
    "        res_words.append(line)\n",
    "\n",
    "    return res_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "def get_lem(word): # на вход одно слово\n",
    "    doc = Doc(word)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)   \n",
    "    doc.tokens[0].lemmatize(morph_vocab) \n",
    "    # если сегментер разделит по дефису то возьмется лемма 1й половины\n",
    "    lem = doc.tokens[0].lemma\n",
    "    \n",
    "    return lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Corpus.'3-gram@_lem' = 'кошка'\",\n",
       " \"Corpus.'3-gram@_orig' = 'нет'\",\n",
       " \"Corpus.'3-gram@_pos' = 'NOUN'\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# норм запрос\n",
    "generate_request('кошек \"нет\" NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "знак + соединяет лемму/словоформу и часть речи. напр.: ехать+NOUN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# не норм запрос\n",
    "generate_request('коше+к \"нет\" NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Corpus.'3-gram@_lem' = 'кошка'\",\n",
       " \"Corpus.'3-gram@_orig' = 'не+т'\",\n",
       " \"Corpus.'3-gram@_pos' = 'NOUN'\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ок запрос\n",
    "generate_request('кошек \"не+т\" NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Попробуйте закрыть двойные кавычки\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# незакрытые кавычки\n",
    "generate_request('кошек \"нет NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(input_s):\n",
    "    input_s = re.sub('\\s+', ' ', input_s).strip() # замена повт пробелов на один\n",
    "    check = len(input_s.split(' '))\n",
    "    if check > 3 or check < 1:\n",
    "        return 'Запрос некорректен'\n",
    "    \n",
    "    words = generate_request(input_s)\n",
    "    if words == []:\n",
    "        return 'Запрос некорректен'\n",
    "        \n",
    "    if check == 1:\n",
    "        request = one_word_requests(words)\n",
    "        print_scentences(request)\n",
    "    elif check == 2:\n",
    "        request = two_words_requests(words)\n",
    "        print_scentences(request)\n",
    "    elif check == 3:\n",
    "        request = three_words_requests(words)\n",
    "        print_scentences(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sents_id(case, c): # на вход id sents\n",
    "    for el in case:\n",
    "        req = \"SELECT sent_orig, title_link FROM Sentences WHERE Sentences.'sent_id' = \" + str(el[0])\n",
    "        sent_orig, title_link = c.execute(req).fetchone()\n",
    "        print('SENT: ' + sent_orig + '\\n' + 'TITLE+URL: ' + title_link)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scentences(request):\n",
    "    conn = sqlite3.connect('project_db.db')\n",
    "    c = conn.cursor()\n",
    "    case = c.execute(request).fetchall()\n",
    "    if case == []:\n",
    "        print('По вашему запросу было найдено НИЧЕГО')\n",
    "    else:\n",
    "        extract_sents_id(case, c)\n",
    "    c.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_word_requests(words): # на вход list, ключи индексы 0, 1 или 2\n",
    "    one_w_req = words[0]\n",
    "    requests = []\n",
    "    for index in range(3):\n",
    "        ending = re.sub('@', str(index), one_w_req)\n",
    "        requests.append(ending)\n",
    "    res = 'SELECT DISTINCT sent FROM Corpus WHERE ' + ' OR '.join(requests) \n",
    "    # distinct чтобы без повторов\n",
    "    \n",
    "    return res # возвращает 1 запрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пример получаемого запроса в базу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT DISTINCT sent FROM Corpus WHERE Corpus.'3-gram0_lem' = 'кошка' OR Corpus.'3-gram1_lem' = 'кошка' OR Corpus.'3-gram2_lem' = 'кошка'\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_word_requests(generate_request('кошек'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_words_requests(words):\n",
    "    requests = []\n",
    "    indexes = [[0, 1], [1, 2]]\n",
    "    for pair in indexes:\n",
    "#         beginning = 'SELECT DISTINCT sent FROM Corpus WHERE '\n",
    "        middle = re.sub('@', str(pair[0]), words[0])\n",
    "        conj = ' AND '\n",
    "        ending = re.sub('@', str(pair[1]), words[1])\n",
    "        requests.append('(' + middle + conj + ending + ')')\n",
    "    \n",
    "    res = 'SELECT DISTINCT sent FROM Corpus WHERE ' + ' OR '.join(requests) \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пример получаемого запроса в базу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT DISTINCT sent FROM Corpus WHERE (Corpus.'3-gram0_lem' = 'кошка' AND Corpus.'3-gram1_pos' = 'NOUN') OR (Corpus.'3-gram1_lem' = 'кошка' AND Corpus.'3-gram2_pos' = 'NOUN')\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_words_requests(generate_request('кошек NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_words_requests(words):\n",
    "#     requests = []\n",
    "#     indexes = [0, 1, 2]\n",
    "    beginning = 'SELECT DISTINCT sent FROM Corpus WHERE '\n",
    "    middle_first = re.sub('@', '0', words[0])\n",
    "    middle_second = re.sub('@', '1', words[1])\n",
    "    conj = ' AND '\n",
    "    ending = re.sub('@', '2', words[2])\n",
    "    res = beginning + middle_first + conj + middle_second + conj + ending\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пример получаемого запроса в базу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT DISTINCT sent FROM Corpus WHERE Corpus.'3-gram0_lem' = 'кошка' AND Corpus.'3-gram1_pos' = 'NOUN' AND Corpus.'3-gram2_lem' = 'поить' AND Corpus.'3-gram2_pos' = 'VERB'\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_words_requests(generate_request('кошек NOUN поить+VERB'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# запуск!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### примеры запросов\n",
    "Приведите примеры запросов, которые можно задавать к вашему корпусу. \n",
    "\n",
    "(Ещё можно описать тематику, чтобы проверяющий мог придумать свои запросы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Попробуйте закрыть двойные кавычки\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Запрос некорректен'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('\"как дела\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT: Партия зеленых предложила ввести ограничение скорости 130 км/ч на немецких автобанах, с целью сократить количество выхлопных газов.\n",
      "TITLE+URL: Ограничениям скорости на немецких автобанах не бывать!\n",
      "https://liveberlin.ru/news/2019/11/04/ogranicheniyam-skorosti-na-nemetskih-avtobanah-ne-byvat/\n",
      "\n",
      "SENT: По опросам, в Британии лидирует созданная в начале апреля этого года «Партия Brexit», занимающая крайне жесткую позицию в поддержку выхода страны из союза.\n",
      "TITLE+URL: Великобритания примет участие в выборах в Европарламент несмотря на Brexit\n",
      "https://liveberlin.ru/news/2019/05/09/velikobritaniya-primet-uchastie-v-vyborah-v-evroparlament-nesmotrya-na-brexit/\n",
      "\n",
      "SENT: Партия этих рыбешек прибыла в начале марта из Гамбурга, куда они в свою очередь были доставлены с Атлантического побережья Франции, сообщает Berliner Morgenpost.\n",
      "TITLE+URL: Экология: В берлинские реки выпустят два миллиона угрей\n",
      "https://liveberlin.ru/news/2019/03/19/ekologiya-v-berlinskie-reki-vypustyat-dva-milliona-ugrej/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search('\"Партия\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По вашему запросу было найдено НИЧЕГО\n"
     ]
    }
   ],
   "source": [
    "search('\"Партия\" VERB ADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT: Читать далее →\n",
      "TITLE+URL: Берлинские круглосуточные магазины (Spätis) отныне будут закрыты по воскресеньям\n",
      "https://liveberlin.ru/news/2019/07/11/berlinskie-kruglosutochnye-magaziny-spatis-otnyne-budut-zakryty-po-voskresenyam/\n",
      "\n",
      "SENT: Читать далее →\n",
      "TITLE+URL: Суд признал незаконными дополнительные открытые для торговли воскресенья в Берлине\n",
      "https://liveberlin.ru/news/2019/04/16/sud-priznal-nezakonnymi-dopolnitelnye-otkrytye-dlya-torgovli-voskresenya-v-berline/\n",
      "\n",
      "SENT: Читать далее →\n",
      "TITLE+URL: Германии нужны 260 000 трудовых мигрантов ежегодно\n",
      "https://liveberlin.ru/news/2019/02/27/germanii-nuzhny-260-tysyach-trudovyh-migrantov-ezhegodno/\n",
      "\n",
      "SENT: Читать далее →\n",
      "TITLE+URL: Полтора миллиона рабочих мест пустуют на немецком рынке труда\n",
      "https://liveberlin.ru/news/2019/02/26/poltora-milliona-rabochih-mest-pustuyut-na-nemetskom-rynke-truda/\n",
      "\n",
      "SENT: Читать далее →\n",
      "TITLE+URL: У посетителей берлинских судов в прошлом году изъяли 22 тысячи единиц оружия и опасных предметов\n",
      "https://liveberlin.ru/news/2019/02/20/u-posetitelej-berlinskih-sudov-v-proshlom-godu-izyali-22-000-edinits-oruzhiya-i-opasnyh-predmetov/\n",
      "\n",
      "SENT: Читать далее → Текущий показатель — самый высокий с момента введения выдачи рабочих виз по программе Blue Card в 2012 году.\n",
      "TITLE+URL: Если работать в ЕС — то в Германии: страна с огромным отрывом лидирует по количеству выданных Blue Card\n",
      "https://liveberlin.ru/news/2019/06/13/esli-rabotat-v-es-to-v-germanii-strana-s-ogromnym-otryvom-lidiruet-po-kolichestvu-vydannyh-blue-card/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search('читать далее')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT: Теперь, при помощи онлайн-ресурса, часть информации стала доступной каждому: для поиска достаточно ввести фамилию человека.\n",
      "TITLE+URL: 13 миллионов документов о преступлениях национал-социалистов стали доступны онлайн\n",
      "https://liveberlin.ru/news/2019/08/19/13-millionov-dokumentov-o-prestupleniyah-natsional-sotsialistov-stali-dostupny-onlajn/\n",
      "\n",
      "SENT: Раздел поиска доступен на пяти языках, в том числе и на русском.\n",
      "TITLE+URL: 13 миллионов документов о преступлениях национал-социалистов стали доступны онлайн\n",
      "https://liveberlin.ru/news/2019/08/19/13-millionov-dokumentov-o-prestupleniyah-natsional-sotsialistov-stali-dostupny-onlajn/\n",
      "\n",
      "SENT: Если соискатель не захочет или не сможет выполнять волонтерскую работу, он может от нее отказаться и дальше получать пособие или социальную помощь, а также продолжать поиски желаемого места.\n",
      "TITLE+URL: Берлинские безработные, которые не могут найти работу больше года, смогут трудоустроиться как волонтеры\n",
      "https://liveberlin.ru/news/2019/08/11/berlinskie-bezrabotnye-kotorye-ne-mogut-najti-rabotu-bolshe-goda-smogut-trudoustroitsya-kak-volontery/\n",
      "\n",
      "SENT: В принятой редакции некоторые ее пункты немного смягчены, например: Сторонники нововведений подчеркивают, что они заставят интернет-гигантов вроде Google и Facebook поделиться прибылями с авторами и правообладателями контента, использование которого в результатах поиска или в лентах пользователей позволяет компаниям зарабатывать на рекламе.\n",
      "TITLE+URL: Жесткая директива об авторском праве принята Европарламентом с небольшими послаблениями\n",
      "https://liveberlin.ru/news/2019/03/27/zhestkaya-direktiva-ob-avtorskom-prave-prinyata-evroparlamentom-s-nebolshimi-poslableniyami/\n",
      "\n",
      "SENT: В баварской столице, по данным сервиса для поиска недвижимости Immowelt, средняя (медианная) стоимость квадратного метра по сравнению с 2017 годом выросла на 6% и превысила 18 евро.\n",
      "TITLE+URL: Immowelt: Стоимость аренды жилья в немецких городах достигла рекордного уровня\n",
      "https://liveberlin.ru/news/2019/02/04/stoimost-arendy-zhilya-v-nemetskih-gorodah-dostigla-rekordnogo-urovnya/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search('поиск')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По вашему запросу было найдено НИЧЕГО\n"
     ]
    }
   ],
   "source": [
    "search('\"поиск\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По вашему запросу было найдено НИЧЕГО\n"
     ]
    }
   ],
   "source": [
    "search('знать+NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По вашему запросу было найдено НИЧЕГО\n"
     ]
    }
   ],
   "source": [
    "search('NOUN VERB ADVB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT: Определяющей исторической причиной этого специалисты называют значительно пострадавший или полностью разрушенный жилой фонд в годы Второй мировой войны и последующее бурное строительство многоквартирных домов под аренду как в ГДР, так и в ФРГ.\n",
      "TITLE+URL: Более половины немцев живут в съемном жилье\n",
      "https://liveberlin.ru/news/2019/03/06/bolee-poloviny-nemtsev-zhivut-v-semnom-zhile/\n",
      "\n",
      "SENT: Решение действует в ситуациях, когда для высокоскоростного подключения того или иного дома к интернету Deutsche Telekom применяет технологию Super-Vectoring (возможная скорость до 250 Mbit/s), а альтернативный провайдер предоставляет услуги оптоволоконной сети по стандарту G.fast (порядка 1 GBit/s).\n",
      "TITLE+URL: Deutsche Telekom сможет ограничивать работу других интернет-провайдеров и даже полностью отключать их\n",
      "https://liveberlin.ru/news/2019/01/23/deutsche-telekom-smozhet-ogranichivat-rabotu-drugih-internet-provajderov-i-dazhe-polnostyu-otklyuchat-ih/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search('ADJ дом')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT: В сентябре 2019 года уполномоченная по защите данных и свободе информации Берлина Майя Смольчик (Maja Smoltczyk, Berliner Beauftragte für Datenschutz und Informationsfreiheit) оштрафовала сервис доставки еды Delivery Hero на 200 000 евро.\n",
      "TITLE+URL: Регламент о защите данных (DSGVO/GDPR) заработал в Германии в полную силу. И это очень жестко\n",
      "https://liveberlin.ru/news/2019/10/30/reglament-o-zaschite-dannyh-dsgvo-gdpr-zarabotal-v-germanii-v-polnuyu-silu-i-eto-ochen-zhestko/\n",
      "\n",
      "SENT: Delivery Hero пытались списать эти случаи на технические сбои или ошибки своих сотрудников, но берлинская уполномоченная по защите данных оказалась сурова: она заявила, что эти нарушения вызваны «фундаментальными, структурными организационными проблемами».\n",
      "TITLE+URL: Регламент о защите данных (DSGVO/GDPR) заработал в Германии в полную силу. И это очень жестко\n",
      "https://liveberlin.ru/news/2019/10/30/reglament-o-zaschite-dannyh-dsgvo-gdpr-zarabotal-v-germanii-v-polnuyu-silu-i-eto-ochen-zhestko/\n",
      "\n",
      "SENT: * * * Случай Delivery Hero поднял планку штрафов на новый уровень — уполномоченная надеется, что они послужат предостережением для других компаний.\n",
      "TITLE+URL: Регламент о защите данных (DSGVO/GDPR) заработал в Германии в полную силу. И это очень жестко\n",
      "https://liveberlin.ru/news/2019/10/30/reglament-o-zaschite-dannyh-dsgvo-gdpr-zarabotal-v-germanii-v-polnuyu-silu-i-eto-ochen-zhestko/\n",
      "\n",
      "SENT: Tagesspiegel опубликовал подробную инфографику о состоянии дел с доступом к 4G по всем немецким регионам.\n",
      "TITLE+URL: Связь 4G в Германии лучше, чем в Сенегале, но хуже, чем в Марокко\n",
      "https://liveberlin.ru/news/2019/08/21/svyaz-4g-v-germanii-luchshe-chem-v-senegale-no-huzhe-chem-v-marokko/\n",
      "\n",
      "SENT: Центр документации о преследованиях национал-социалистским режимом «Архивы Арользена», работающий при поддержке израильского национального мемориала Катастрофы (Холокоста) и Героизма Яд Вашем (יד ושם), открыл онлайн-доступ к 13 миллионам документов.\n",
      "TITLE+URL: 13 миллионов документов о преступлениях национал-социалистов стали доступны онлайн\n",
      "https://liveberlin.ru/news/2019/08/19/13-millionov-dokumentov-o-prestupleniyah-natsional-sotsialistov-stali-dostupny-onlajn/\n",
      "\n",
      "SENT: Deutsche Bank планирует ликвидировать 18 тысяч рабочих мест по всему миру до 2022 года в связи с реорганизацией, сообщает Welt.\n",
      "TITLE+URL: Deutsche Bank сократит 18 тысяч сотрудников\n",
      "https://liveberlin.ru/news/2019/07/22/deutsche-bank-sokratit-18-tysyach-sotrudnikov/\n",
      "\n",
      "SENT: Но, согласно плану, Deutsche Bank хочет сэкономить 17 миллиардов евро к 2022 году и выйти из кризиса.\n",
      "TITLE+URL: Deutsche Bank сократит 18 тысяч сотрудников\n",
      "https://liveberlin.ru/news/2019/07/22/deutsche-bank-sokratit-18-tysyach-sotrudnikov/\n",
      "\n",
      "SENT: Железнодорожный концерн Deutsche Bahn упраздняет экономичный билет выходного дня Schönes-Wochenende-Ticket (SWT) c 9 июня 2019 год.\n",
      "TITLE+URL: Железнодорожный билет выходного дня Schönes-Wochenende-Ticket будет упразднен c 9 июня\n",
      "https://liveberlin.ru/news/2019/06/07/zheleznodorozhnyj-bilet-vyhodnogo-dnya-schones-wochenende-ticket-budet-uprazdnen-c-9-iyunya/\n",
      "\n",
      "SENT: Онлайн-петицию за снижение НДС на средства женской личной гигиены на сайте change.org подписали более 170 тысяч человек.\n",
      "TITLE+URL: Вопрос о снижении НДС на средства личной гигиены для женщин будет рассмотрен в парламенте\n",
      "https://liveberlin.ru/news/2019/06/04/vopros-o-snizhenii-nds-na-sredstva-lichnoj-gigieny-dlya-zhenschin-budet-rassmotren-v-parlamente/\n",
      "\n",
      "SENT: Так, признана незаконной работа столичных магазинов по воскресеньям во время январской Международной зеленой недели (Grüne Woche), февральского кинофестиваля Берлинале (Berlinale), мартовской Международной туристической ярмарки (Internationale Tourismus-Börse) и сентябрьской Недели искусства (Berlin Art Week), сообщает официальный городской сайт.\n",
      "TITLE+URL: Суд признал незаконными дополнительные открытые для торговли воскресенья в Берлине\n",
      "https://liveberlin.ru/news/2019/04/16/sud-priznal-nezakonnymi-dopolnitelnye-otkrytye-dlya-torgovli-voskresenya-v-berline/\n",
      "\n",
      "SENT: Парламентская оппозиция, а также Ассоциация немецких студентов (Deutsche Studentenwerk), приветствуют изменения, однако считают их недостаточными.\n",
      "TITLE+URL: Государственные студенческие стипендии (BAföG) планируют увеличить со следующего учебного года\n",
      "https://liveberlin.ru/news/2019/02/14/gosudarstvennye-studencheskie-stipendii-bafog-planiruyut-uvelichit-so-sleduyuschego-uchebnogo-goda/\n",
      "\n",
      "SENT: Берлинский сенат и концерн Deutsche Telekom заключили соглашение об оснащении нескольких регионов столицы высокоскоростной мобильной связью стандарта 5G до 2021 года, сообщает Tagesspiegel.\n",
      "TITLE+URL: Сверхбыстрая мобильная связь стандарта 5G появится в Берлине до 2021 года, обещают сенат и Telekom\n",
      "https://liveberlin.ru/news/2019/02/06/sverhbystraya-mobilnaya-svyaz-standarta-5g-poyavitsya-v-berline-do-2021-goda-obeschayut-senat-i-telekom/\n",
      "\n",
      "SENT: Решение действует в ситуациях, когда для высокоскоростного подключения того или иного дома к интернету Deutsche Telekom применяет технологию Super-Vectoring (возможная скорость до 250 Mbit/s), а альтернативный провайдер предоставляет услуги оптоволоконной сети по стандарту G.fast (порядка 1 GBit/s).\n",
      "TITLE+URL: Deutsche Telekom сможет ограничивать работу других интернет-провайдеров и даже полностью отключать их\n",
      "https://liveberlin.ru/news/2019/01/23/deutsche-telekom-smozhet-ogranichivat-rabotu-drugih-internet-provajderov-i-dazhe-polnostyu-otklyuchat-ih/\n",
      "\n",
      "SENT: Deutsche Telekom отстаивает свое право, ссылаясь на то, что является правопреемником организации Deutsche Bundespost, которая до 1987 года владела всей немецкой телефонной сетью и даже всеми телефонными аппаратами.\n",
      "TITLE+URL: Deutsche Telekom сможет ограничивать работу других интернет-провайдеров и даже полностью отключать их\n",
      "https://liveberlin.ru/news/2019/01/23/deutsche-telekom-smozhet-ogranichivat-rabotu-drugih-internet-provajderov-i-dazhe-polnostyu-otklyuchat-ih/\n",
      "\n",
      "SENT: Немецкий железнодорожный концерн Deutsche Bahn заключил с профсоюзом GDL новый коллективный трудовой договор.\n",
      "TITLE+URL: Забастовок на немецких железных дорогах не будет до 2021 года\n",
      "https://liveberlin.ru/news/2019/01/07/zabastovok-na-nemetskih-zheleznyh-dorogah-ne-budet-do-2021-goda/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search('X VERB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### бонусы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бонус - если вы придумали какие-то оптимизации, чтобы поиск работал быстрее, не забудьте сказать о них :)\n",
    "\n",
    "Ещё бонус - разбор ошибок, которые делает функция поиска\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если jupyter-тетрадка, то можно ссылку на гитхаб.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Crawler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
